---
title:  "Statistics for Data Science"
date:   2019-4-7
layout: single
author_profile: true
comments: true
tags:
---

![](https://pix-media.priceonomics-media.com/blog/1234/Fisher1946.JPG)
> Ronald A. Fisher, father of modern statistics, enjoying his pipe.

## The 5 Basic Statistics Concepts Data Scientists Need to Know

1. *Statistical Features* 記述統計
2. *Probability Distributions* 確率分布
3. *Dimensionality Reduction* 次元削除
4. *Over and Under Sampling* 標本サイズ、区間推定
5. *Bayesian Statistics* ベイズ統計

## 統計学

1. 記述統計学と基礎統計
2. 確率分布
3. 推測的統計 from 推測統計学
4. 仮説検定 from 推測統計学
5. ベイズ統計学
6. Advanced Stats

## トピック

1. 記述統計学と基礎統計

	- 統計学の全体感
	- 記述統計指標まとめ
	- 標準偏差と分散
	- 統計的前処理
	- 多重共線性
	- 最小二乗法
	- 損失関数
	- 離散型と連続型データ
	- 統計学とグラフ（箱ひげとヒストグラム, 散布図）

2. 確率分布

	- Population and Sample
	- 正規分布
	- 確率分布の種類: 二項分布、多項分布、連続一様分布、T分布
	- 確率と面積: 率確率密度関数(PDF)
	- 中心極限定理

3. 推測的統計 from 推測統計学

	- Bias vs. Variance
	- 最尤推定 vs. MAP推定
	- 信頼区間と区間推定
	- パラメータとバイアス
	- 推量と推定

4. 仮説検定 from 推測統計学

	- 有意水準と帰無仮説
	- T検定とZ検定
	- パラメトリック検定 vs. ノンパラメトリック検定

5. ベイズ統計学

	- ベイズの定理

6. Advanced Topic

	- 次元削除
	- 正則化
	- 時系列データにおける統計学
	- 交差エントロピー誤差


# 1. 記述統計学と基礎統計

## 統計学の全体感

1. 記述統計学（データの要約値・可視化）
2. 推測統計学(モデル作成)
	- 統計的推定（）
	- 仮説検定（信頼区間、P値、t検定）
3. ベイズ統計学

## 記述統計指標まとめ
## 標準偏差と分散
## 統計的前処理

- 前処理1：欠損値の対応(Missing Data)
- 前処理2：外れ値の対応(Outlier Detection)
- 前処理3：連続値の離散化(Sampling)
- 前処理4：データ操作(Data Wrangling)
- 前処理5：ダミー変数(Dummies)

## 多重共線性



## 最小二乗法

- 最小二乗法 ＝ 等分散ガウス分布 ＋ 最尤推定

## 損失関数


## 離散型と連続型データ



## 統計学とグラフ（箱ひげとヒストグラム, 散布図）


# 2. 確率分布

## Population and Sample

- 母集団とサンプル（無作為抽出と確率）
- 未来のデータを含む全データと過去のデータ（未来のデータは未知・確率的）

## 正規分布

- 正規分布を知れば「その発生確率を計算できる現象」がグッと増えてくるということ
- 正規分布とはランダムな分布、未知なものに仮定

- 正規分布を前提にしている. Why?
	- 自然界
	- 中心極限定理
	- シンプル

	平均値と最頻値と中央値が一致*する。
	平均値を中心にして左右対称である。（直線# x=μに関して対称）
	x軸が漸近線である。
	分散（標準偏差）が大きくなると、曲線の山は低くなり、左右に広がって平らになる。分散（標準偏差）が小さくなると、山は高くなり、よりとんがった形になる。

## 確率分布の種類: 二項分布、多項分布、連続一様分布、T分布

- 二項分布（独立離散確率分布）
- サンプル数が多いと正規分布になるよ

## 確率と面積: 率確率密度関数(PDF)

- 確率密度関数(確率=面積)

## 中心極限定理

- 中心極限定理 = 複数の変数の分布が正規分布に近づく


# 3. 推測的統計 from 推測統計学

## 推量と推定

- 推定
	- 点推定
	- 区間推定

## Bias vs. Variance
## 最尤推定 vs. MAP推定

- 最尤法
	- データ（分布）を固定してパラメータを動かす <-> 普通：
	- 尤度関数を最大化するθ探し（argmax）

- 点推定
	- 最尤法 = (事前情報)
	- MAP推定 = 最尤法 + 事後情報

## 信頼区間と区間推定
## パラメータとバイアス


# 4. 仮説検定 from 推測統計学

## 有意水準と帰無仮説

- 検定
	- 帰無仮説:
	- 有意水準:

## T検定とZ検定
## パラメトリック検定 vs. ノンパラメトリック検定


# 5. ベイズ統計学

## ベイズの定理

- ベイズの定理 = 条件付き確率 + 乗法定理（加法定理）
- 確率分布
	- ベイズ定理() = 最尤法 + 事後情報
	- 最適化

# 6. Advanced Topic

## 次元削除
## 正則化
## 時系列データにおける統計学
## 交差エントロピー誤差
























- データの分布が分かれば
- 発生確率が分かれば
- 予測可能になる
- あとは異なる変数間の関係だけを調べろ

- Confidence Intervals vs. Prediction Interval
-




統計学とは？

統計学 vs. 機械学習

- 手法は変わらない、目的が違う
- ソフトウェアと統計学の出会い
- 作業の代替が得意

- 統計学＝分布
- 分布＝確率分布

モデルというのは、そもそも確率変数と確率分オプが分かれば説明できる

人工知能における研究課題の一つで、人間 が自然に行っている学習能力と同様の機能をコンピュ ータで実現しようとする技術・手法のことである。

コンピュータが目を持った。

汎用性と過学習
バイアスと分散（variance）
正則化（Regularization）
ベイズ
最尤推定とマップ推定
リッジとラッソ
注意：標準化（Standardization, Normalization）

本によってはペナルティー項などとも書かれており、要するに最小化を実行しようとしたときに、第一項だけを小さくできたとしても、第二項が大きくなるのはダメというペナルティーを与えて、wの値を考えなおさせることができるわけです。

正則化というのは、ベイズ統計での事前分布に概念上も定式化の上でもほぼ対応しています。つまり、正則化なしの機械学習がベイズ統計における最尤推定（MSE） 、正則化ありの機械学習がベイズ統計における最大事後確率推定（MAP）に対応します。

機械学習というのは、データからモデルの未知パラメータを推定する手法なわけですが、正則化というのは、未知パラメータについて事前に持っている知識（あるいは、こうなったいるべきだという要請）を勘案することです。


正則化は、多くの場合は、最適化の目的関数に制約（事前知識）を表す項を追加するという形で定式化されますが、それ以外の手法もたくさんあります。

有名なのは、L1正則化と、L2正則化ですかね。L1正則化は、パラメータの絶対値の和（L1ノルム）を小さくするという条件を課すもので、こうすることでスパース（多くのパラメータがゼロになって、少数のパラメータのみが値をとる）な結果が得られます。

L2正則化は、最も単純にパラメータのL2ノルムを小さくする（パラメータ値があまり大きな値をとらないようにする）という条件を課すものです。


## 「データの扱い」
という観点からは、「データがモデルを磨き上げるための訓練の素材になる」という点が機械学習の特徴です。

## 一方で統計学では、「データが生まれる背景」に真っ先に着目します
「十分数のデータが従う傾向」のことを「母集団分布」と呼びます。
統計学手法の特徴は、*データについて何かを説明する前に、母集団分布に関する仮定をまず置く*、という点にあります。

## 「データが生じる背景（i.e. 母集団分布）」を特定化してから分析を進めているということです。
 今回の場合、統計学に基づく異常値検出のシステムは、下記のような流れで設計・実装が出来るでしょう。

1. 製品重量の分布は正規分布に従うと仮定する
2. データからその平均値と、データのばらつきを表す値（分散）を推定
3. 推定された平均値と分散を基に、重量に基づく異常値検出のシステムを実装


勾配効果法で次元数が莫大
連立方程式では無理、計算量オーバー
少しずつ計算したい


# 推定と検定

### 検定検定では、データに対する仮定がそもそも成り立つのかを判断しようという試みです。

推定との違いを強調すると、推定では「データにある分布を仮定し、その分布のパラメータを計算する」が、検定では「ある分布のパラメータの仮定を先に置き、その仮定が正しいかどうかをデータを用いて判断する」と言えます。


## 推定は、あるパラメータがこれぐらいの値だろうということしか言えず、確実とは言えません。例えば「平均は8.6」と推定により得られても、あくまで予想であるということです。

 * 「平均は8.6」という値を算出するのが点推定と呼ばれる方法です。
* 「95%の確率で、平均は8.4〜8.8」だと算出するのが区間推定と言います。

推定を行うための方法はかなり確立されていますが、当然、*ある分布に従うと考えた場合の「ある分布」が全く見当違いであるならば、推定(パラメータの計算)をしても実りある知見は得られないことに注意しましょう。*

分布がわからない
↓
当てずっぽう（確率に従っている）

分布がわかっている前提での予測モデル

更に、データがある分布に従うとしたときに、その分布のパラメータを計算するのが推定でしたが、「データが(本当に)ある分布に従うか否かを判断する」という検定を行うこともできます(コロモゴロフ・スミノルフ検定)。


*近年の応用の立場からすると、新規のデータに対する予測を行えるように、手元のデータから規則性を学習する技術を機械学習だと言えるでしょう。*

予測がす

区間推定：分散が既知な場合





- [How To Ace Data Science Interviews: Statistics](https://towardsdatascience.com/how-to-ace-data-science-interviews-statistics-f3d363ad47b)
- [Top 45 Data Science Interview Questions You Must Prepare In 2019](https://www.edureka.co/blog/interview-questions/data-science-interview-questions/)
- [Statistics Interview Questions | Useful And Most Asked](https://www.educba.com/statistics-interview-questions/)
- []()
- []()
- []()
